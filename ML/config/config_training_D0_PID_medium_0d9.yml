input:
  prompt:
    [/home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/sample/McTreeForMLPromptTrain_303753.root]
  FD:
    [/home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/sample/McTreeForMLFDTrain_303753.root]
  data: [/home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/sample/DataTreeForMLTrain_303753.root]
  treename: TreeForML

data_prep:
  channel: D0ToKPi # options: D0ToKPi, DplusToPiKPi, DsToKKPi, LcToPKPi, XicToPKPi
  filt_bkg_mass: fM > 1.65 & fM < 2.1   # pandas query to select bkg candidates
  class_balance:
    option: equal # change how the dataset is built, options available: 'equal', 'max_signal'
      # 'equal' -> same number of prompt/FD/bkg (not using all the signal available)
      # 'max_signal' -> try to use all the signal (prompt and FD) + add n_bkg = 2 * (n_prompt + n_FD)
    # bkg_factor: [1., 1., 1., 1., 1., 1.] # list of multipliers for (nPrompt + nFD) used to determine nCandBkg in the 'max_signal' option
    bkg_factor: [1., 1., 1., 1., 1., 1.]
  seed_split: 42  
  #test_fraction: 0.3
  test_fraction: 0.1

pt_ranges:
  min: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 16]  # list
  max: [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 16, 24]  # list

ml:
  raw_output: false
  roc_auc_approach: ovo
  roc_auc_average: macro
  # training_vars: [fDecayLength, fDecayLengthXY, fCpa, fCpaXY, fImpactParameterProduct]
  # training_vars: [fCpa, fCpaXY, fDecayLength, fDecayLengthXY, fImpactParameterProduct]
  # training_vars: ["fCpa", "fCpaXY", 
  # "fDecayLength", "fDecayLengthXY",
  #   "fImpactParameterProduct",
  #     "fNSigTpcTofPi0", "fNSigTpcTofPi1", "fNSigTpcTofKa0", "fNSigTpcTofKa1"]""
  # training_vars: [cpa, cpaXY, decayLength, decayLengthXY, impactParameterProduct]
  training_vars: ["fCpa", "fCpaXY", "fDecayLengthXY", "fDecayLengthXYNormalised", "fImpactParameterProduct","fNSigTpcTofPiExpPi", "fNSigTpcTofKaExpKa"]

  hyper_pars: [
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    }, 
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    },
    {
      "max_depth": 4,
      "learning_rate": 0.01,
      "n_estimators": 1000,
      "min_child_weight": 5,
      "n_jobs": 24,
      "tree_method": hist,
    } 
    
    ]
  hyper_pars_opt:
    # activate: false
    activate: true
    ntrials: 10
    njobs: 30
    timeout: 1800
    hyper_par_ranges:
      {
        "max_depth": !!python/tuple [3, 5],
        "learning_rate": !!python/tuple [0.005, 0.025],
        "n_estimators": !!python/tuple [300, 1800],
        "min_child_weight": !!python/tuple [1, 10],
        "subsample": !!python/tuple [0.7, 1.],
        "colsample_bytree": !!python/tuple [0.7, 1.]
      }
  saved_models: [
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt0_1/ModelHandler_D0ToKPi_pT_0_1.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt1_2/ModelHandler_D0ToKPi_pT_1_2.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt2_3/ModelHandler_D0ToKPi_pT_2_3.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt3_4/ModelHandler_D0ToKPi_pT_3_4.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt4_5/ModelHandler_D0ToKPi_pT_4_5.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt5_6/ModelHandler_D0ToKPi_pT_5_6.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt6_7/ModelHandler_D0ToKPi_pT_6_7.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt7_8/ModelHandler_D0ToKPi_pT_7_8.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt8_10/ModelHandler_D0ToKPi_pT_8_10.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt10_12/ModelHandler_D0ToKPi_pT_10_12.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt12_16/ModelHandler_D0ToKPi_pT_12_16.pickle,
            /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/pt16_24/ModelHandler_D0ToKPi_pT_16_24.pickle
          ]


output:
  # dir: Training_PID_meds_hp
  # dir: applys
  #dir: Models_test/test
  # dir: ModelForTest
  dir: /home/wuct/ALICE/local/DmesonAnalysis/RTools/ML/results/Training_303753/
  leg_labels: # legend labels, keep the right number of classes
    Bkg: Background
    Prompt: Prompt
    FD: NonPrompt
  out_labels: # output labels, keep the right number of classes
    Bkg: Bkg
    Prompt: Prompt
    FD: NonPrompt
  
plots:
    # plotting_columns: ["fDecayLength", "fDecayLengthXY", "fCpa", "fCpaXY", "fImpactParameterProduct", "fM", "fPt"]

    plotting_columns: [
    "fCpa",
    "fCpaXY",
    "fDecayLengthXY",
    "fDecayLengthXYNormalised",
    "fNSigTpcTofPiExpPi",
    "fNSigTpcTofKaExpKa",
    "fDecayLength",
    "fImpactParameterProduct",
    "fDecayLengthNormalised",
    "fPtProng0",
    "fPtProng1",
    "fImpactParameter0",
    "fImpactParameter1",
    "fImpactParameterNormalised0",
    "fImpactParameterNormalised1",
    "fNSigTpcPiExpPi",
    "fNSigTpcKaExpKa",
    "fNSigTofPiExpPi",
    "fNSigTofKaExpKa",
    "fCosThetaStar",
    "fCt",
    "fM",
    "fPt"]
    # plotting_columns: ["cpa", "cpaXY", "decayLength", "decayLengthXY", "impactParameterProduct", "fM", "fPt"]
                       # list of variables to plot
    train_test_log: True # use log scale for plots of train and test distributions

apply: 
    # column_to_save_list: ["fDecayLength", "fDecayLengthXY", "fCpa", "fCpaXY", "fImpactParameterProduct", "fM", "fPt"]
    column_to_save_list: [ 
          "fM",
    "fPt",
"fCpa", "fCpaXY", "fDecayLengthXY", "fDecayLengthXYNormalised", "fCosThetaStar", "fImpactParameterProduct","fNSigTpcTofPiExpPi", "fNSigTpcTofKaExpKa"]
    # column_to_save_list: ["cpa", "cpaXY", "decayLength", "decayLengthXY", "impactParameterProduct", "fM", "fPt"]
    # list of variables saved in the dataframes with the applied models 